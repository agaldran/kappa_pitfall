{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e5e1258",
   "metadata": {},
   "source": [
    "### What's this\n",
    "This short notebook serves as a demonstration of a pitfall of the quadratically-weighted kappa metric for evaluation purposes on image grading tasks. Specifically, it varies quite heavily in the presence of label shift (when label distribution changes over time/space, see [this link](https://d2l.ai/chapter_multilayer-perceptrons/environment.html#label-shift) for definition). We will also see that accuracy and balanced accuracy are unaffected by this, and Matthews Correlation Coefficient is affected, but much less than Quad Kappa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b12eb8",
   "metadata": {},
   "source": [
    "### Let's start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f5b1c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import cohen_kappa_score, matthews_corrcoef, accuracy_score\n",
    "from sklearn.metrics import balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc53246",
   "metadata": {},
   "source": [
    "Let us generate a synthetic dataset with 500 samples labeled with classes 0,1,2,3,4, as is typical in diabetic retinopathy grading. In this dataset there are 100 examples of each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55d2c5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array(100*[0] + 100*[1] + 100*[2] + 100*[3] + 100*[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762a3c30",
   "metadata": {},
   "source": [
    "We now build a synthetic model that 400 over 500 times predicts the true category, but on the remaining 100 samples it predicts randomly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b16a564f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy labels over predictions\n",
    "y_pred = y_true.copy()\n",
    "# pick 100 positions on y_pred to replace label by random prediction\n",
    "replaced_pred_inds = np.random.choice(len(y_true), size=100, replace=False)\n",
    "# replaced labels by random predictions on those positions\n",
    "y_pred[replaced_pred_inds] = np.random.randint(0,4+1, size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a566cb",
   "metadata": {},
   "source": [
    "The model is pretty decent on all four metrics. Note that because the dataset is perfectly balanced, accuracy and balanced accuracy are exactly the same in this case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d269f061",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quad-kappa=80.45, MCC=78.28, ACC=82.60, bal-ACC=82.60,\n"
     ]
    }
   ],
   "source": [
    "k = cohen_kappa_score(y_true, y_pred, weights='quadratic')\n",
    "mcc = matthews_corrcoef(y_true, y_pred)\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "b_acc = balanced_accuracy_score(y_true, y_pred)\n",
    "print('Quad-kappa={:.2f}, MCC={:.2f}, ACC={:.2f}, bal-ACC={:.2f},'.format(100*k, 100*mcc, 100*acc, 100*b_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34f9837",
   "metadata": {},
   "source": [
    "Let us use the same model on a different dataset that has different prevalences. This dataset also has 500 samples, but categories 3 and 4 are less represented, and category 0 is much more represented:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4151ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array(280*[0] + 100*[1] + 100*[2] + 10*[3] + 10*[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81bcb38",
   "metadata": {},
   "source": [
    "The model is the same as before, 80% of the time it says the truth, 20% it is random:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "837ef05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy labels over predictions\n",
    "y_pred = y_true.copy()\n",
    "# pick 100 positions on y_pred to replace label by random prediction\n",
    "replaced_pred_inds = np.random.choice(len(y_true), size=100, replace=False)\n",
    "# replaced labels by random predictions on those positions\n",
    "y_pred[replaced_pred_inds] = np.random.randint(0,4+1, size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775e98ed",
   "metadata": {},
   "source": [
    "We look again at the same four metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3381625",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quad-kappa=61.14, MCC=75.88, ACC=84.00, bal-ACC=80.14,\n"
     ]
    }
   ],
   "source": [
    "k = cohen_kappa_score(y_true, y_pred, weights='quadratic')\n",
    "mcc = matthews_corrcoef(y_true, y_pred)\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "b_acc = balanced_accuracy_score(y_true, y_pred)\n",
    "print('Quad-kappa={:.2f}, MCC={:.2f}, ACC={:.2f}, bal-ACC={:.2f},'.format(100*k, 100*mcc, 100*acc, 100*b_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ae8edd",
   "metadata": {},
   "source": [
    "We can see that accuracy is very robust to label shift, and so appears to be Matthews Correlation Coefficient, but quadratic kappa varies dramatically. I\n",
    "\n",
    "Also, if we run the above cell multiple times, we will also see that balanced accuracy is quite volatile, as the model making a few more or less mistakes in minority classes result in heavy improvements or degradations of this metric.\n",
    "\n",
    "Just to check that this was not a random coincidence, let us run this experiment 1000 times and look at the statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb589f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EXPERIMENTS = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "512fa64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_performance(y_true):\n",
    "    # copy labels over predictions\n",
    "    y_pred = y_true.copy()\n",
    "    # pick 100 positions on y_pred to replace label by random prediction\n",
    "    replaced_pred_inds = np.random.choice(len(y_true), size=100, replace=False)\n",
    "    # replaced labels by random predictions on those positions\n",
    "    y_pred[replaced_pred_inds] = np.random.randint(0,4+1, size=100)\n",
    "    \n",
    "    k = cohen_kappa_score(y_true, y_pred, weights='quadratic')\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    b_acc = balanced_accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    return k, mcc, acc, b_acc\n",
    "    \n",
    "ks_balanced, mccs_balanced = np.zeros((N_EXPERIMENTS,)), np.zeros((N_EXPERIMENTS,))\n",
    "accs_balanced, bal_accs_balanced = np.zeros((N_EXPERIMENTS,)), np.zeros((N_EXPERIMENTS,))\n",
    "\n",
    "ks_imbalanced, mccs_imbalanced = np.zeros((N_EXPERIMENTS,)), np.zeros((N_EXPERIMENTS,))\n",
    "accs_imbalanced, bal_accs_imbalanced = np.zeros((N_EXPERIMENTS,)), np.zeros((N_EXPERIMENTS,))\n",
    "\n",
    "for ex in range(N_EXPERIMENTS):\n",
    "    # balanced dataset\n",
    "    y_true = np.array(100*[0] + 100*[1] + 100*[2] + 100*[3] + 100*[4])\n",
    "    k, mcc, acc, bal_acc = get_model_performance(y_true)\n",
    "    \n",
    "    ks_balanced[ex], mccs_balanced[ex], accs_balanced[ex], bal_accs_balanced[ex] = k, mcc, acc, bal_acc\n",
    "    \n",
    "    # imbalanced dataset - label shift\n",
    "    y_true = np.array(280*[0] + 100*[1] + 100*[2] + 10*[3] + 10*[4])\n",
    "    k, mcc, acc, bal_acc = get_model_performance(y_true)\n",
    "    \n",
    "    ks_imbalanced[ex], mccs_imbalanced[ex], accs_imbalanced[ex], bal_accs_imbalanced[ex] = k, mcc, acc, bal_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6f09786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BALANCED DATASET:\n",
      "Avg Quad-kappa    = 80.09+/-2.27\n",
      "Avg MCC           = 80.03+/-1.01\n",
      "Avg Accuracy      = 84.00+/-0.81\n",
      "Avg Bal. Accuracy = 84.00+/-0.81\n",
      "----------------------------------------\n",
      "IMBALANCED DATASET:\n",
      "Avg Quad-kappa    = 62.77+/-3.37\n",
      "Avg MCC           = 75.80+/-1.18\n",
      "Avg Accuracy      = 84.02+/-0.81\n",
      "Avg Bal. Accuracy = 83.91+/-3.19\n"
     ]
    }
   ],
   "source": [
    "print('BALANCED DATASET:')\n",
    "print('Avg Quad-kappa    = {:.2f}+/-{:.2f}'.format(100*ks_balanced.mean(), 100*ks_balanced.std()))\n",
    "print('Avg MCC           = {:.2f}+/-{:.2f}'.format(100*mccs_balanced.mean(), 100*mccs_balanced.std()))\n",
    "print('Avg Accuracy      = {:.2f}+/-{:.2f}'.format(100*accs_balanced.mean(), 100*accs_balanced.std()))\n",
    "print('Avg Bal. Accuracy = {:.2f}+/-{:.2f}'.format(100*bal_accs_balanced.mean(), 100*bal_accs_balanced.std()))\n",
    "\n",
    "print(40*'-')\n",
    "\n",
    "print('IMBALANCED DATASET:')\n",
    "print('Avg Quad-kappa    = {:.2f}+/-{:.2f}'.format(100*ks_imbalanced.mean(), 100*ks_imbalanced.std()))\n",
    "print('Avg MCC           = {:.2f}+/-{:.2f}'.format(100*mccs_imbalanced.mean(), 100*mccs_imbalanced.std()))\n",
    "print('Avg Accuracy      = {:.2f}+/-{:.2f}'.format(100*accs_imbalanced.mean(), 100*accs_imbalanced.std()))\n",
    "print('Avg Bal. Accuracy = {:.2f}+/-{:.2f}'.format(100*bal_accs_imbalanced.mean(), 100*bal_accs_imbalanced.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72caf61",
   "metadata": {},
   "source": [
    "Note that even if on average balanced accuracy and accuracy are similar in the long run, the standard devation of the balanced accuracies is much larger; it is even higher than the standard deviation of the quadratic kappa!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce5a100",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "If one has datasets from different regions or different moments in time, one should be careful with comparing the performance of the same model on those using the quadratric kappa metric, since this is not an apples to apples comparison. It would be wiser to use accuracy instead, or MCC. It is also interesting to note that Balanced Accuracy is only a fair metric for a large number of datasets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
